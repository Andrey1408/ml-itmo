{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3S4O/Yrx/ept+Qq27p571"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hmzkXUh_nJC","executionInfo":{"status":"ok","timestamp":1681513227474,"user_tz":-180,"elapsed":5046,"user":{"displayName":"Andrey лю","userId":"16082555664786964240"}},"outputId":"85ca50fb-17a8-4bf8-d67f-dd99025ec034"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0]\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","import pandas as pd\n","import numpy as np\n","import re\n","\n","train = pd.read_csv('titanic_train.csv')\n","x_train = train.drop('survived', axis=1)\n","y_train = train['survived']\n","x_test = pd.read_csv('titanic_reserved.csv')\n","\n","cols_to_delete = ['ticket']\n","for col in x_train.columns:\n","    if (x_train[col].isna().sum() / len(x_train) > 1/3): cols_to_delete.append(col)\n","x_train.drop(cols_to_delete, axis=1, inplace=True)\n","x_test.drop(cols_to_delete, axis=1, inplace=True)\n","\n","replacements = {\n","    'Mr': ['Rev', 'Col', 'Dr', 'Major', 'Don', 'Capt'],\n","    'Mrs': ['Dona', 'Countess'],\n","    'Miss': ['Mlle', 'Ms']\n","}\n","\n","def make_honorific(x):\n","    honorific = re.search(r' (\\S+?)\\. ', x).group(1)    \n","\n","    for k in replacements:\n","        if (honorific in replacements[k]): return k\n","    \n","    return honorific\n","\n","x_train['honorific'] = x_train['name'].apply(make_honorific)\n","x_test['honorific'] = x_test['name'].apply(make_honorific)\n","\n","x_train['age'] = x_train.groupby('honorific')['age'].transform(lambda x: x.fillna(x.mean()))\n","x_test['age'] = x_test.groupby('honorific')['age'].transform(lambda x: x.fillna(x.mean()))\n","\n","x_train.drop(['honorific', 'name'], axis=1, inplace=True)\n","x_test.drop(['honorific', 'name'], axis=1, inplace=True)\n","\n","dummies = pd.get_dummies(x_train.select_dtypes(exclude=np.number), prefix=x_train.select_dtypes(exclude=np.number).columns, drop_first=True)\n","x_train[dummies.columns] = dummies\n","x_train.drop(x_train.select_dtypes(exclude=np.number).columns, axis=1, inplace=True)\n","dummies = pd.get_dummies(x_test.select_dtypes(exclude=np.number), prefix=x_test.select_dtypes(exclude=np.number).columns, drop_first=True)\n","x_test[dummies.columns] = dummies\n","x_test.drop(x_test.select_dtypes(exclude=np.number).columns, axis=1, inplace=True)\n","\n","lre = LogisticRegression(max_iter=1000)\n","lre.fit(x_train, y_train)\n","y_pred = lre.predict(x_test)\n","\n","print(list(y_pred))"]}]}